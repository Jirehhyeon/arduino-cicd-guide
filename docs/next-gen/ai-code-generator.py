#!/usr/bin/env python3
"""
ğŸ¤– AI-Powered Arduino Code Generator
ìì—°ì–´ ì„¤ëª…ì„ Arduino ì½”ë“œë¡œ ìë™ ë³€í™˜í•˜ëŠ” GPT-4o ê¸°ë°˜ ì‹œìŠ¤í…œ
"""

import openai
import ast
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import json
import asyncio
import websockets
from datetime import datetime

@dataclass
class HardwareSpec:
    """í•˜ë“œì›¨ì–´ ì‚¬ì–‘ ì •ì˜"""
    board: str  # "ESP32", "Arduino Uno", "Raspberry Pi Pico"
    sensors: List[str]  # ["DHT22", "BMP280", "PIR"]
    actuators: List[str]  # ["Servo", "LED", "Relay"]
    connectivity: List[str]  # ["WiFi", "Bluetooth", "LoRa"]
    power_requirements: str  # "3.3V", "5V", "Battery"

@dataclass
class CodeGenerationRequest:
    """ì½”ë“œ ìƒì„± ìš”ì²­ êµ¬ì¡°"""
    natural_language_description: str
    hardware_spec: HardwareSpec
    target_functionality: List[str]
    optimization_goals: List[str]  # ["energy_efficiency", "response_time", "memory_usage"]
    integration_requirements: List[str]  # ["mqtt", "web_server", "ota_update"]

class AICodeGenerator:
    """GPT-4o ê¸°ë°˜ Arduino ì½”ë“œ ìƒì„±ê¸°"""
    
    def __init__(self, api_key: str):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.code_templates = self._load_templates()
        self.optimization_patterns = self._load_optimization_patterns()
        
    def _load_templates(self) -> Dict[str, str]:
        """ì½”ë“œ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            "esp32_base": """
#include <WiFi.h>
#include <WebServer.h>
#include <ArduinoJson.h>
#include <AsyncMqttClient.h>

// AI ìƒì„± ì„¤ì •
const char* WIFI_SSID = "{wifi_ssid}";
const char* WIFI_PASSWORD = "{wifi_password}";
const char* MQTT_SERVER = "{mqtt_server}";

// í•˜ë“œì›¨ì–´ í•€ ì •ì˜ (AI ìµœì í™”)
{pin_definitions}

// ì „ì—­ ë³€ìˆ˜ (ë©”ëª¨ë¦¬ ìµœì í™”)
{global_variables}

// AI ìƒì„± í•¨ìˆ˜ë“¤
{ai_generated_functions}

void setup() {{
    Serial.begin(115200);
    {setup_code}
}}

void loop() {{
    {loop_code}
}}
""",
            "sensor_reading": """
float read{sensor_name}() {{
    // AI ìµœì í™”ëœ ì„¼ì„œ ì½ê¸°
    {sensor_specific_code}
    return {return_value};
}}
""",
            "smart_automation": """
void smartAutomation() {{
    // AI ê¸°ë°˜ ìë™í™” ë¡œì§
    float prediction = predictNextValue();
    if (prediction > threshold) {{
        {automation_action}
    }}
}}
"""
        }
    
    def _load_optimization_patterns(self) -> Dict[str, str]:
        """ìµœì í™” íŒ¨í„´ ë¡œë“œ"""
        return {
            "energy_efficiency": {
                "deep_sleep": "esp_deep_sleep_start();",
                "wifi_power_save": "WiFi.setSleep(true);",
                "cpu_frequency": "setCpuFrequencyMhz(80);"
            },
            "memory_optimization": {
                "progmem": "const char* data PROGMEM = \"{data}\";",
                "string_optimization": "F(\"string\")",
                "array_pooling": "static uint8_t buffer[256];"
            },
            "performance": {
                "interrupt_optimization": "IRAM_ATTR void fastISR() {}",
                "cache_friendly": "volatile uint32_t* reg = (uint32_t*)address;",
                "dma_transfer": "spi_dma_transfer(data, length);"
            }
        }
    
    async def generate_code(self, request: CodeGenerationRequest) -> Dict[str, any]:
        """ë©”ì¸ ì½”ë“œ ìƒì„± í•¨ìˆ˜"""
        
        # 1. í•˜ë“œì›¨ì–´ ë¶„ì„ ë° ìµœì í™”
        hardware_analysis = await self._analyze_hardware(request.hardware_spec)
        
        # 2. ìì—°ì–´ â†’ ê¸°ëŠ¥ ëª…ì„¸ ë³€í™˜
        functional_spec = await self._parse_natural_language(
            request.natural_language_description,
            request.target_functionality
        )
        
        # 3. AI ì½”ë“œ ìƒì„±
        generated_code = await self._generate_arduino_code(
            functional_spec,
            hardware_analysis,
            request.optimization_goals
        )
        
        # 4. ì½”ë“œ ìµœì í™” ë° ê²€ì¦
        optimized_code = await self._optimize_code(
            generated_code,
            request.optimization_goals
        )
        
        # 5. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™ ìƒì„±
        test_cases = await self._generate_test_cases(optimized_code)
        
        # 6. ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        deployment_script = await self._generate_deployment_script(
            optimized_code,
            request.integration_requirements
        )
        
        return {
            "main_code": optimized_code,
            "test_cases": test_cases,
            "deployment_script": deployment_script,
            "performance_metrics": await self._estimate_performance(optimized_code),
            "energy_analysis": await self._analyze_energy_consumption(optimized_code),
            "security_analysis": await self._security_audit(optimized_code),
            "documentation": await self._generate_documentation(optimized_code)
        }
    
    async def _analyze_hardware(self, spec: HardwareSpec) -> Dict[str, any]:
        """í•˜ë“œì›¨ì–´ ì‚¬ì–‘ ë¶„ì„ ë° ìµœì í™” ì œì•ˆ"""
        
        prompt = f"""
        í•˜ë“œì›¨ì–´ ì‚¬ì–‘ì„ ë¶„ì„í•˜ê³  ìµœì í™” ì œì•ˆì„ ìƒì„±í•˜ì„¸ìš”:
        
        ë³´ë“œ: {spec.board}
        ì„¼ì„œ: {', '.join(spec.sensors)}
        ì•¡ì¶”ì—ì´í„°: {', '.join(spec.actuators)}
        ì—°ê²°ì„±: {', '.join(spec.connectivity)}
        ì „ì›: {spec.power_requirements}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”:
        {{
            "pin_mapping": {{"sensor_name": "pin_number"}},
            "power_analysis": {{"estimated_current": "mA", "battery_life": "hours"}},
            "performance_constraints": ["constraint1", "constraint2"],
            "optimization_recommendations": ["recommendation1", "recommendation2"]
        }}
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì„ë² ë””ë“œ í•˜ë“œì›¨ì–´ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        return json.loads(response.choices[0].message.content)
    
    async def _parse_natural_language(self, description: str, functionality: List[str]) -> Dict[str, any]:
        """ìì—°ì–´ ì„¤ëª…ì„ ê¸°ëŠ¥ ëª…ì„¸ë¡œ ë³€í™˜"""
        
        prompt = f"""
        ë‹¤ìŒ ìì—°ì–´ ì„¤ëª…ì„ êµ¬ì²´ì ì¸ Arduino ê¸°ëŠ¥ ëª…ì„¸ë¡œ ë³€í™˜í•˜ì„¸ìš”:
        
        ì„¤ëª…: {description}
        ëª©í‘œ ê¸°ëŠ¥: {', '.join(functionality)}
        
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        {{
            "main_functions": [
                {{
                    "name": "function_name",
                    "description": "ê¸°ëŠ¥ ì„¤ëª…",
                    "inputs": ["input1", "input2"],
                    "outputs": ["output1"],
                    "timing_requirements": "ì‹¤ì‹œê°„/ì£¼ê¸°ì /ì´ë²¤íŠ¸ê¸°ë°˜",
                    "error_handling": "ì˜¤ë¥˜ ì²˜ë¦¬ ë°©ë²•"
                }}
            ],
            "data_structures": [
                {{
                    "name": "struct_name",
                    "fields": ["{{"type": "float", "name": "temperature"}}"]
                }}
            ],
            "communication_protocols": ["WiFi", "MQTT", "HTTP"],
            "timing_constraints": {{"max_response_time": "100ms"}}
        }}
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì„ë² ë””ë“œ ì‹œìŠ¤í…œ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        
        return json.loads(response.choices[0].message.content)
    
    async def _generate_arduino_code(self, 
                                   functional_spec: Dict[str, any],
                                   hardware_analysis: Dict[str, any],
                                   optimization_goals: List[str]) -> str:
        """ì‹¤ì œ Arduino ì½”ë“œ ìƒì„±"""
        
        # ìµœì í™” ëª©í‘œì— ë”°ë¥¸ ì½”ë“œ ìŠ¤íƒ€ì¼ ê²°ì •
        optimization_directives = []
        for goal in optimization_goals:
            if goal == "energy_efficiency":
                optimization_directives.append("ì „ë ¥ ì†Œëª¨ ìµœì†Œí™”ë¥¼ ìœ„í•´ deep sleep ëª¨ë“œ ì‚¬ìš©")
            elif goal == "response_time":
                optimization_directives.append("ì¸í„°ëŸ½íŠ¸ ê¸°ë°˜ ë¹ ë¥¸ ì‘ë‹µ êµ¬í˜„")
            elif goal == "memory_usage":
                optimization_directives.append("PROGMEM ì‚¬ìš© ë° ë©”ëª¨ë¦¬ í’€ë§")
        
        prompt = f"""
        ë‹¤ìŒ ëª…ì„¸ì— ë”°ë¼ ìµœì í™”ëœ Arduino C++ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”:
        
        ê¸°ëŠ¥ ëª…ì„¸: {json.dumps(functional_spec, indent=2)}
        í•˜ë“œì›¨ì–´ ë¶„ì„: {json.dumps(hardware_analysis, indent=2)}
        ìµœì í™” ëª©í‘œ: {', '.join(optimization_directives)}
        
        ìš”êµ¬ì‚¬í•­:
        1. ì™„ì „í•œ Arduino ìŠ¤ì¼€ì¹˜ (.ino íŒŒì¼)
        2. ì—ëŸ¬ ì²˜ë¦¬ ë° ì˜ˆì™¸ ìƒí™© ëŒ€ì‘
        3. ì£¼ì„ìœ¼ë¡œ ì½”ë“œ ì„¤ëª…
        4. ëª¨ë“ˆí™”ëœ í•¨ìˆ˜ êµ¬ì¡°
        5. ì„±ëŠ¥ ìµœì í™” ì ìš©
        6. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
        7. ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
        8. OTA ì—…ë°ì´íŠ¸ ì§€ì›
        
        ì½”ë“œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì—†ì´):
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ Arduino ê°œë°œìì…ë‹ˆë‹¤. ìµœì í™”ë˜ê³  ì•ˆì •ì ì¸ ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=4000
        )
        
        return response.choices[0].message.content
    
    async def _optimize_code(self, code: str, optimization_goals: List[str]) -> str:
        """ìƒì„±ëœ ì½”ë“œ ìµœì í™”"""
        
        optimizations = []
        for goal in optimization_goals:
            if goal in self.optimization_patterns:
                optimizations.extend(self.optimization_patterns[goal].values())
        
        prompt = f"""
        ë‹¤ìŒ Arduino ì½”ë“œë¥¼ ìµœì í™”í•˜ì„¸ìš”:
        
        ì›ë³¸ ì½”ë“œ:
        {code}
        
        ì ìš©í•  ìµœì í™”:
        {chr(10).join(optimizations)}
        
        ìµœì í™”ëœ ì½”ë“œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ì½”ë“œ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1
        )
        
        return response.choices[0].message.content
    
    async def _generate_test_cases(self, code: str) -> List[Dict[str, any]]:
        """ìë™ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±"""
        
        prompt = f"""
        ë‹¤ìŒ Arduino ì½”ë“œì— ëŒ€í•œ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”:
        
        {code}
        
        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤ì„ ì‘ë‹µí•˜ì„¸ìš”:
        {{
            "unit_tests": [
                {{
                    "test_name": "test_sensor_reading",
                    "description": "ì„¼ì„œ ì½ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸",
                    "input_conditions": {{"temperature": 25.0}},
                    "expected_output": {{"success": true, "value": 25.0}},
                    "test_code": "Arduino í…ŒìŠ¤íŠ¸ ì½”ë“œ"
                }}
            ],
            "integration_tests": [
                {{
                    "test_name": "test_wifi_connection",
                    "description": "WiFi ì—°ê²° í†µí•© í…ŒìŠ¤íŠ¸",
                    "setup_requirements": ["WiFi AP í•„ìš”"],
                    "test_steps": ["1. WiFi ì—°ê²° ì‹œë„", "2. ì—°ê²° ìƒíƒœ í™•ì¸"],
                    "expected_behavior": "5ì´ˆ ë‚´ ì—°ê²° ì™„ë£Œ"
                }}
            ],
            "performance_tests": [
                {{
                    "test_name": "test_response_time",
                    "description": "ì‘ë‹µ ì‹œê°„ ì¸¡ì •",
                    "metric": "response_time_ms",
                    "threshold": 100,
                    "test_duration": "60ì´ˆ"
                }}
            ]
        }}
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "í…ŒìŠ¤íŠ¸ ìë™í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        
        return json.loads(response.choices[0].message.content)

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """AI ì½”ë“œ ìƒì„±ê¸° ì‚¬ìš© ì˜ˆì‹œ"""
    
    # AI ì½”ë“œ ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = AICodeGenerator(api_key="your-openai-api-key")
    
    # í•˜ë“œì›¨ì–´ ì‚¬ì–‘ ì •ì˜
    hardware = HardwareSpec(
        board="ESP32",
        sensors=["DHT22", "BMP280", "LDR"],
        actuators=["Servo", "WS2812 LED Strip", "Water Pump"],
        connectivity=["WiFi", "MQTT"],
        power_requirements="3.7V LiPo Battery"
    )
    
    # ì½”ë“œ ìƒì„± ìš”ì²­
    request = CodeGenerationRequest(
        natural_language_description="""
        ìŠ¤ë§ˆíŠ¸ ì‹ë¬¼ ì¬ë°° ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 
        ì˜¨ë„, ìŠµë„, ëŒ€ê¸°ì••, ì¡°ë„ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³ ,
        ì‹ë¬¼ì˜ ìƒíƒœì— ë”°ë¼ ìë™ìœ¼ë¡œ ë¬¼ì„ ì£¼ê³  LED ì¡°ëª…ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.
        ìŠ¤ë§ˆíŠ¸í° ì•±ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆì–´ì•¼ í•˜ê³ ,
        AIê°€ ì‹ë¬¼ ì„±ì¥ íŒ¨í„´ì„ í•™ìŠµí•´ì„œ ìµœì ì˜ í™˜ê²½ì„ ìë™ìœ¼ë¡œ ì¡°ì„±í•´ì£¼ì„¸ìš”.
        """,
        hardware_spec=hardware,
        target_functionality=[
            "ì‹¤ì‹œê°„ ì„¼ì„œ ëª¨ë‹ˆí„°ë§",
            "ìë™ ê¸‰ìˆ˜ ì‹œìŠ¤í…œ",
            "LED ì¡°ëª… ì œì–´",
            "ëª¨ë°”ì¼ ì•± ì—°ë™",
            "AI ê¸°ë°˜ ìµœì í™”"
        ],
        optimization_goals=[
            "energy_efficiency",
            "response_time",
            "memory_usage"
        ],
        integration_requirements=[
            "mqtt",
            "web_server",
            "ota_update",
            "mobile_app_api"
        ]
    )
    
    # AI ì½”ë“œ ìƒì„± ì‹¤í–‰
    print("ğŸ¤– AIê°€ Arduino ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
    result = await generator.generate_code(request)
    
    # ê²°ê³¼ ì €ì¥
    output_dir = Path("generated_code")
    output_dir.mkdir(exist_ok=True)
    
    # ë©”ì¸ ì½”ë“œ ì €ì¥
    with open(output_dir / "smart_plant_system.ino", "w", encoding="utf-8") as f:
        f.write(result["main_code"])
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì €ì¥
    with open(output_dir / "test_cases.json", "w", encoding="utf-8") as f:
        json.dump(result["test_cases"], f, indent=2, ensure_ascii=False)
    
    # ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼
    print(f"ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥: {result['performance_metrics']}")
    print(f"ğŸ”‹ ì „ë ¥ ë¶„ì„: {result['energy_analysis']}")
    print(f"ğŸ›¡ï¸ ë³´ì•ˆ ì ìˆ˜: {result['security_analysis']}")
    
    print("âœ… AI ì½”ë“œ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼: {output_dir}")

if __name__ == "__main__":
    asyncio.run(main())